global:
  resolve_timeout: 5m
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@goleapai.com'
  smtp_auth_username: 'alerts@goleapai.com'
  smtp_auth_password: 'your-password-here'

# Templates for notifications
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Route tree for organizing alerts
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'default-receiver'
  routes:
    # Critical alerts - immediate notification
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 0s
      repeat_interval: 5m
      continue: true

    # Warning alerts - standard notification
    - match:
        severity: warning
      receiver: 'warning-alerts'
      repeat_interval: 1h

    # Info alerts - batched notification
    - match:
        severity: info
      receiver: 'info-alerts'
      group_wait: 5m
      group_interval: 5m
      repeat_interval: 4h

    # Provider-specific alerts
    - match:
        component: provider
      receiver: 'provider-alerts'

    # Cost alerts go to finance team
    - match:
        team: finance
      receiver: 'finance-alerts'

# Alert receivers
receivers:
  - name: 'default-receiver'
    email_configs:
      - to: 'team@example.com'
        headers:
          Subject: '[GoLeapAI] Alert: {{ .GroupLabels.alertname }}'
        html: |
          {{ range .Alerts }}
          <h2>{{ .Labels.alertname }}</h2>
          <p><b>Summary:</b> {{ .Annotations.summary }}</p>
          <p><b>Description:</b> {{ .Annotations.description }}</p>
          <p><b>Severity:</b> {{ .Labels.severity }}</p>
          <p><b>Started:</b> {{ .StartsAt }}</p>
          {{ end }}

  - name: 'critical-alerts'
    email_configs:
      - to: 'oncall@example.com'
        headers:
          Subject: '[CRITICAL] GoLeapAI Alert: {{ .GroupLabels.alertname }}'
    # Add Slack webhook for critical alerts
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#alerts-critical'
        title: '[CRITICAL] {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        send_resolved: true

  - name: 'warning-alerts'
    email_configs:
      - to: 'team@example.com'
        headers:
          Subject: '[WARNING] GoLeapAI Alert: {{ .GroupLabels.alertname }}'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#alerts-warning'
        title: '[WARNING] {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

  - name: 'info-alerts'
    email_configs:
      - to: 'team@example.com'
        headers:
          Subject: '[INFO] GoLeapAI Alert: {{ .GroupLabels.alertname }}'

  - name: 'provider-alerts'
    email_configs:
      - to: 'providers@example.com'
        headers:
          Subject: '[Provider] GoLeapAI Alert: {{ .GroupLabels.alertname }}'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#providers'
        title: '[Provider] {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

  - name: 'finance-alerts'
    email_configs:
      - to: 'finance@example.com'
        headers:
          Subject: '[Cost] GoLeapAI Alert: {{ .GroupLabels.alertname }}'

# Inhibition rules - suppress alerts based on other alerts
inhibit_rules:
  # Suppress warning if critical alert is firing
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']

  # Suppress provider latency alerts if provider is down
  - source_match:
      alertname: 'ProviderDown'
    target_match:
      alertname: 'ProviderLatencyDegradation'
    equal: ['provider']

  # Suppress quota alerts if provider is down
  - source_match:
      alertname: 'ProviderDown'
    target_match:
      alertname: 'QuotaNearLimit'
    equal: ['provider']
